{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oulu_NLPTM_TwitterBrexit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(filename):\n",
    "    tweet_list = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for tweet in f:\n",
    "            tweet_list.append(tweet.strip())\n",
    "            \n",
    "    print(f\"loaded tweets from {filename}\")\n",
    "    return tweet_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded tweets from conservative_tweets_preprocessed.txt\n",
      "loaded tweets from labour_tweets_preprocessed.txt\n"
     ]
    }
   ],
   "source": [
    "conservative_tweets = load(\"conservative_tweets_preprocessed.txt\")\n",
    "labour_tweets = load(\"labour_tweets_preprocessed.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting top 10 frequent words\n",
    "def top10(tweets):\n",
    "    list_of_words = []\n",
    "    for tweet in tweets:\n",
    "        words = tweet.split()\n",
    "        list_of_words.append(words)\n",
    "    flat_list = [item for sublist in list_of_words for item in sublist]\n",
    "\n",
    "    word_counts = Counter(flat_list)\n",
    "    return word_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP10 words by conservatives: \n",
      "1. wordstem:'thank' occurences: 1128\n",
      "2. wordstem:'work' occurences: 1052\n",
      "3. wordstem:'today' occurences: 1045\n",
      "4. wordstem:'peopl' occurences: 1003\n",
      "5. wordstem:'support' occurences: 981\n",
      "6. wordstem:'great' occurences: 943\n",
      "7. wordstem:'get' occurences: 857\n",
      "8. wordstem:'help' occurences: 673\n",
      "9. wordstem:'busi' occurences: 617\n",
      "10. wordstem:'local' occurences: 602\n",
      "\n",
      "TOP10 words by labour: \n",
      "1. wordstem:'support' occurences: 1059\n",
      "2. wordstem:'govern' occurences: 988\n",
      "3. wordstem:'thank' occurences: 936\n",
      "4. wordstem:'peopl' occurences: 849\n",
      "5. wordstem:'need' occurences: 801\n",
      "6. wordstem:'work' occurences: 675\n",
      "7. wordstem:'pleas' occurences: 643\n",
      "8. wordstem:'today' occurences: 586\n",
      "9. wordstem:'get' occurences: 564\n",
      "10. wordstem:'test' occurences: 524\n"
     ]
    }
   ],
   "source": [
    "top10_conservative = top10(conservative_tweets)\n",
    "top10_labour = top10(labour_tweets)\n",
    "print('TOP10 words by conservatives: ')\n",
    "for i, word in enumerate(top10_conservative):\n",
    "    print(str(i+1) + \". wordstem:'\" +  str(word[0]) + \"' occurences: \" + str(word[1]))\n",
    "\n",
    "print()\n",
    "print('TOP10 words by labour: ')\n",
    "for i, word in enumerate(top10_labour):\n",
    "    print(str(i+1) + \". wordstem:'\" +  str(word[0]) + \"' occurences: \" + str(word[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'peopl', 'thank', 'busi', 'great', 'today', 'local', 'support', 'get', 'help', 'work'}\n",
      "{'peopl', 'govern', 'thank', 'need', 'today', 'pleas', 'support', 'test', 'get', 'work'}\n",
      "Jaccard distance based on TOP10 most frequent words: 0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "top10_conservative_wordset = set([word[0] for word in top10_conservative])\n",
    "top10_labour_wordset = set([word[0] for word in top10_labour])\n",
    "\n",
    "jaccard_index_top10 = nltk.jaccard_distance(top10_conservative_wordset, top10_labour_wordset)\n",
    "\n",
    "print('Jaccard distance based on TOP10 most frequent words: ' + str(jaccard_index_top10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
